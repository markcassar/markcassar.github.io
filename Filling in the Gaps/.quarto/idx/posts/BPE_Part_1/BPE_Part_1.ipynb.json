{"title":"Understanding Byte Pair Encoding: Part 1: Encodings","markdown":{"yaml":{"title":"Understanding Byte Pair Encoding: Part 1: Encodings","author":"Mark Cassar","date":"18 December 2024","format":{"html":{"code-fold":false}}},"headingText":"Understanding Byte Pair Encoding: Part 1: Encodings","containsRefs":false,"markdown":"\n\n\nMy goal is to get a deeper understanding of tokenization as it relates to the preprocessing of text for input into a large language model (LLM). I had heard of byte pair encoding (BPE) but became more interested as I was reading Sebastian Raschka's book [Build a Large Language Model (from Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch) (highly recommended). I then came across Andrej Karpathy's incredible set of lectures [From Zero to Hero](https://karpathy.ai/zero-to-hero.html), which includes a video on building the GPT2 tokenizer. \n\nWhat I am doing here is nothing original, just my attempt to process and understand as fully as possible the concepts I have been learning recently. \n\nSo, let's start with some text:\n\nUnfortunately, text is never just 'text'; there must be a mapping between binary numbers and characters, since all computers store information as binary numbers. \n\nWhen I look into the [Python documentation](https://docs.python.org/3/library/stdtypes.html#textseq), I discover that Python handles text as `str` (or string) objects; and further, that *\"Strings are immutable sequences of Unicode code points.\"* To access the Unicode code points, we can use the `ord()` function.\n\nThe [Unicode standard](https://home.unicode.org/) is an attempt to create a single system to represent all characters used in human communication. That is, to allow people to talk to each other how they naturally would regardless of the device they are using. This means the characters of all human languages, as well as things like emojis and mathematical symbols: \n\nThe standard consists of assigning a unique **code point** to each character. This is not an actual encoding, as it does not specify how this gets implemented on any computer hardware. Python displays these code points as decimal numbers, although the standard uses the notation `U+` followed by a hexadecimal value. \n\nSo the two characters above would have code points `U+1F600` and `U+27FA`, respectively ('0x' is how Python designates a hexadecimal value).\n\nNow, since Unicode is not an encoding, my question was, how does Python know how to get from the characters to the code points? I think the answer is specified in the [docs](https://docs.python.org/3/library/stdtypes.html#textseq): *\"A Unicode string is a sequence of code points, which are numbers from 0 through 0x10FFFF (1,114,111 decimal). This sequence of code points needs to be represented in memory as a set of code units, and code units are then mapped to 8-bit bytes. The rules for translating a Unicode string into a sequence of bytes are called a character encoding, or just an encoding.\"*\n\nIt seems the answer is that Python assumes the text is encoded using [**UTF-8**](https://en.wikipedia.org/wiki/UTF-8) and that the encoding is done natively under the hood. UTF stands for *Unicode Transformation Format* and the 8 stands for 8-bit. \n\nThe conversion between Unicode code points and UTF-8 is given the table from the Wikipedia page listed above:\n\n<a id=\"utf8-conversion\"></a>\n\n<!-- ![unicode_to_utf8](images/UTF-8.png) -->\n<img src=\"UTF-8.png\">\n\nI need to keep a couple things in mind here:\n- UTF-8 operates at the single byte level, and\n- Unicode code points range from `U+0000` to `U+10FFFF`, which in integers is from 0 to 1114111 (`int(0x10ffff)`, noting that 0x10ffff is Python's hexadecimal equivalent to U+10FFFF)\n\nGiven the range of code points, this means that UTF-8 needs more than one byte to represent any code point above (theoretically) 255; However, UTF-8 uses more than one byte to represent any code point above 127. This is done to maintain backward compatibility with [ASCII](https://en.wikipedia.org/wiki/ASCII), which only used values from 0 to 127. \n\nTo see this in action, I'll modify the text so it includes characters that require 1, 2, 3, and 4 bytes in UTF-8: \n\nNow I want to see the code points for these characters, also noting that there are 18 characters in the text.\n\nFor the moment, I want to look at the code points that are above 127, which are 1009, 2332, and 128512. Looking up these code points will often require the hexadecimal equivalent: \n- 1009 = 0x3f1 = U+3F1\n- 2332 = 0x91c = U+91C\n- 128512 = 0x1f600 = U+1F600\n\nTo clarify this, I will note the equivalence mathematically. First, I note again that the prefix '0x' is Python's way of denoting a hexadecimal number. Thus, the values after that define the actual number. Second, I need to remember that in hexadecimal, we need to use the first few characters of the alphabet to represent the numbers from 10 to 15, so A=10, B=11, C=12, D=13, E=14, and F=15. So, we have:\n\n$$\n\\begin{align*}\n\\rm{0x3f1} &= 3 \\times 16^2 + 15 \\times 16^1 + 1 \\times 16^0 \\\\\n&= 3 \\times 256 + 15 \\times 16 + 1 \\times 1 \\\\\n&= 768 + 240 + 1 \\\\\n&= 1009\\\\\n\\\\\n\\rm{0x91c} &= 9 \\times 16^2 + 1 \\times 16^1 + 12 \\times 16^0 \\\\\n&= 9 \\times 256 + 1 \\times 16 + 12 \\times 1 \\\\\n&= 2304 + 16 + 12 \\\\\n&= 2332\\\\\n\\\\\n\\rm{0x1f600} &= 1 \\times 16^4 + 15 \\times 16^3 + 6 \\times 16^2 + 0 \\times 16^1 + 0 \\times 16^0 \\\\\n&= 1 \\times 65536 + 15 \\times 4096 + 6 \\times 256 + 0 + 0 \\\\\n&= 65536 + 61440 + 1536 \\\\\n&= 128512\n\\end{align*}\n$$\n\nI can also check the correspondence between these code point values and the characters that printed using the following tables: \n- for 1009 see [Greek and Coptic](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Greek_and_Coptic)\n- for 2332 (use hex value U+91C) see [Devanagari](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Devanagari)\n- for 128512 (use hex value  U+1F600) see [Emoji](https://en.wikipedia.org/wiki/Emoji#Unicode_blocks)\n\nNow when I look at the same text encoded in UTF-8, I see:\n\nI now have 24 bytes, instead of 18 characters, and notice that all of the code point values are below 256 (which is expected if every value comes from a single byte). What I find confusing is reconciling this with what I just did above. To make sense of it, I need to recall the code point to UTF-8 conversion table above, and bring in binary numbers. \n\nNote what happens when I try to convert the UTF-8 encoded bytes as if they were code points: \n\nEverything is ok up until we hit the Greek letter rho, Ï±. The problem here is that `chr()` is the reverse of `ord()` and so it only operates properly on code points, not UTF-8 bytes. To see this, we can use our earlier code point values:\n\nThat looks better! But how do I reconcile these two approaches. I'll first isolate our \"problem\" characters.\n\nI know that a space character, \" \", is represented by code point 32, so it seems that we have: \n1. Ï± somehow equivalent to two code points 207, 177\n2. à¤œ somehow equivalent to three code points 224, 164, 156\n3. ðŸ˜€somehow equivalent to the four code points 240, 159, 152, 128\n\n\nFor item 1 we could try:\n\nor\n\nNeither of those give the correct output. To get this to work I need to follow the UTF-8 guidelines for converting to Unicode code points (see [table above](#utf8-conversion)). So for the Greek letter, let's take a look at the byte values in binary and use the table to convert.\n<!-- ![unicode_to_utf8](UTF-8.png) -->\n\nThe $\\rm{\\textcolor{red}{0b}}$ is Python's designation for binary digit, and it is left out of the conversion table. So, instead of 207 and 177, we can deal 11001111 and 10110001. Now we can follow the UTF-8 encoding. The $\\textcolor{blue}{110}$ at the beginning of the first number is a code to indicate that the character requires two bytes ($\\textcolor{blue}{1110}$ if it requires three bytes and $\\textcolor{blue}{11110}$ if it requires four bytes). Any byte beginning with a $\\textcolor{blue}{10}$ denotes to Python that it belongs to a sequence of either 2, 3, or 4 bytes, and that it is NOT the starting byte (the source of many UnicodeDecodeErrors). Using this system, I get the following for Ï±:\n\n$$\n\\begin{align*}\n207 \\,\\, 177 &= \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{110}\\, 01111 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 110001 \\\\\n\\\\\n\\rm{binary\\,code\\, point\\, for\\,207\\,177}&= 01111 \\,\\,\\, 110001 \\\\\n&= 01111110001  \\\\\n\\rm{decimal\\,code\\, point\\, for\\,207\\,177}&= 0 \\times 2^{10} + 1 \\times 2^9 + 1 \\times 2^8 + 1 \\times 2^7 + 1 \\times 2^6 + 1 \\times 2^5 + 1 \\times 2^4 + 0 \\times 2^3 + 0 \\times 2^2 + 0 \\times 2^1 + 1 \\times 2^0 \\\\\n&= 0 + 512 + 256 + 128 + 64 + 32 + 16 + 0 + 0 + 0 + 1 \\\\\n&= 1009\n\\end{align*}\n$$\n\nAnd just to validate that calculation:\n\nThis approach, then, provides a mechanism from going from stored binary digits to Unicode code points. \n\nSince I am a skeptical person, I want to see if this works for my other two \"problem\" characters. This time, however, I will leave out the direct conversion to decimal values. For these two characters, I have the following byte values:\n\nFor à¤œ, I get the following:\n\n$$\n\\begin{align*}\n224 \\,\\, 164\\,\\,156 &= \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{1110}\\, 0000 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 100100 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 011100\\\\\n\\\\\n\\rm{binary\\,code\\, point\\, for\\,224 \\,\\ 164\\,\\,156}&= 0000 \\,\\,\\, 100100 \\,\\,\\, 011100 \\\\\n&= 0000100100011100  \\\\\n\\end{align*}\n$$\n\nwhich equals\n\nAnd for ðŸ˜€, I get:\n\n\n$$\n\\begin{align*}\n240\\,\\,159 \\,\\, 152\\,\\,128 &= \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{11110}\\, 000 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 011111 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 011000 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\,000000\\\\\n\\\\\n\\rm{binary\\,code\\, point\\, for\\,240\\,\\,159 \\,\\, 152\\,\\,128}&= 000 \\,\\,\\, 011111 \\,\\,\\, 011000 \\,\\,\\, 000000 \\\\\n&= 000011111011000000000  \\\\\n\\end{align*}\n$$\n\nwhich is\n\nSo, I can see that everything is working as it is supposed to. \n\nBefore wrapping up this part of my journey, I want to mention that UTF-8 is not the only encoding scheme. UTF-16 and UTF-32 also exist. However, since UTF-8 seems to be the [dominant encoding scheme](https://w3techs.com/technologies/overview/character_encoding) at the moment, I won't venture into the lands of UTF-16 and UTF-32. \n\nAnd the last point I want to make is that the 2, 3, and 4 byte sequences used in UTF-8 are linked bytes, so all is well if I execute\n\nBut not so good if I execute this\n\nThis is because the inserted space character is not a valid continuation byte according the the UTF-8 scheme. \n\nWell, that is it for the first part of my journey to dig into the details of BPE. Some aspects of encoding are still a bit murky, but I think I grasp enough at the moment to move on. \n","srcMarkdownNoYaml":"\n\n## Understanding Byte Pair Encoding: Part 1: Encodings\n\nMy goal is to get a deeper understanding of tokenization as it relates to the preprocessing of text for input into a large language model (LLM). I had heard of byte pair encoding (BPE) but became more interested as I was reading Sebastian Raschka's book [Build a Large Language Model (from Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch) (highly recommended). I then came across Andrej Karpathy's incredible set of lectures [From Zero to Hero](https://karpathy.ai/zero-to-hero.html), which includes a video on building the GPT2 tokenizer. \n\nWhat I am doing here is nothing original, just my attempt to process and understand as fully as possible the concepts I have been learning recently. \n\nSo, let's start with some text:\n\nUnfortunately, text is never just 'text'; there must be a mapping between binary numbers and characters, since all computers store information as binary numbers. \n\nWhen I look into the [Python documentation](https://docs.python.org/3/library/stdtypes.html#textseq), I discover that Python handles text as `str` (or string) objects; and further, that *\"Strings are immutable sequences of Unicode code points.\"* To access the Unicode code points, we can use the `ord()` function.\n\nThe [Unicode standard](https://home.unicode.org/) is an attempt to create a single system to represent all characters used in human communication. That is, to allow people to talk to each other how they naturally would regardless of the device they are using. This means the characters of all human languages, as well as things like emojis and mathematical symbols: \n\nThe standard consists of assigning a unique **code point** to each character. This is not an actual encoding, as it does not specify how this gets implemented on any computer hardware. Python displays these code points as decimal numbers, although the standard uses the notation `U+` followed by a hexadecimal value. \n\nSo the two characters above would have code points `U+1F600` and `U+27FA`, respectively ('0x' is how Python designates a hexadecimal value).\n\nNow, since Unicode is not an encoding, my question was, how does Python know how to get from the characters to the code points? I think the answer is specified in the [docs](https://docs.python.org/3/library/stdtypes.html#textseq): *\"A Unicode string is a sequence of code points, which are numbers from 0 through 0x10FFFF (1,114,111 decimal). This sequence of code points needs to be represented in memory as a set of code units, and code units are then mapped to 8-bit bytes. The rules for translating a Unicode string into a sequence of bytes are called a character encoding, or just an encoding.\"*\n\nIt seems the answer is that Python assumes the text is encoded using [**UTF-8**](https://en.wikipedia.org/wiki/UTF-8) and that the encoding is done natively under the hood. UTF stands for *Unicode Transformation Format* and the 8 stands for 8-bit. \n\nThe conversion between Unicode code points and UTF-8 is given the table from the Wikipedia page listed above:\n\n<a id=\"utf8-conversion\"></a>\n\n<!-- ![unicode_to_utf8](images/UTF-8.png) -->\n<img src=\"UTF-8.png\">\n\nI need to keep a couple things in mind here:\n- UTF-8 operates at the single byte level, and\n- Unicode code points range from `U+0000` to `U+10FFFF`, which in integers is from 0 to 1114111 (`int(0x10ffff)`, noting that 0x10ffff is Python's hexadecimal equivalent to U+10FFFF)\n\nGiven the range of code points, this means that UTF-8 needs more than one byte to represent any code point above (theoretically) 255; However, UTF-8 uses more than one byte to represent any code point above 127. This is done to maintain backward compatibility with [ASCII](https://en.wikipedia.org/wiki/ASCII), which only used values from 0 to 127. \n\nTo see this in action, I'll modify the text so it includes characters that require 1, 2, 3, and 4 bytes in UTF-8: \n\nNow I want to see the code points for these characters, also noting that there are 18 characters in the text.\n\nFor the moment, I want to look at the code points that are above 127, which are 1009, 2332, and 128512. Looking up these code points will often require the hexadecimal equivalent: \n- 1009 = 0x3f1 = U+3F1\n- 2332 = 0x91c = U+91C\n- 128512 = 0x1f600 = U+1F600\n\nTo clarify this, I will note the equivalence mathematically. First, I note again that the prefix '0x' is Python's way of denoting a hexadecimal number. Thus, the values after that define the actual number. Second, I need to remember that in hexadecimal, we need to use the first few characters of the alphabet to represent the numbers from 10 to 15, so A=10, B=11, C=12, D=13, E=14, and F=15. So, we have:\n\n$$\n\\begin{align*}\n\\rm{0x3f1} &= 3 \\times 16^2 + 15 \\times 16^1 + 1 \\times 16^0 \\\\\n&= 3 \\times 256 + 15 \\times 16 + 1 \\times 1 \\\\\n&= 768 + 240 + 1 \\\\\n&= 1009\\\\\n\\\\\n\\rm{0x91c} &= 9 \\times 16^2 + 1 \\times 16^1 + 12 \\times 16^0 \\\\\n&= 9 \\times 256 + 1 \\times 16 + 12 \\times 1 \\\\\n&= 2304 + 16 + 12 \\\\\n&= 2332\\\\\n\\\\\n\\rm{0x1f600} &= 1 \\times 16^4 + 15 \\times 16^3 + 6 \\times 16^2 + 0 \\times 16^1 + 0 \\times 16^0 \\\\\n&= 1 \\times 65536 + 15 \\times 4096 + 6 \\times 256 + 0 + 0 \\\\\n&= 65536 + 61440 + 1536 \\\\\n&= 128512\n\\end{align*}\n$$\n\nI can also check the correspondence between these code point values and the characters that printed using the following tables: \n- for 1009 see [Greek and Coptic](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Greek_and_Coptic)\n- for 2332 (use hex value U+91C) see [Devanagari](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Devanagari)\n- for 128512 (use hex value  U+1F600) see [Emoji](https://en.wikipedia.org/wiki/Emoji#Unicode_blocks)\n\nNow when I look at the same text encoded in UTF-8, I see:\n\nI now have 24 bytes, instead of 18 characters, and notice that all of the code point values are below 256 (which is expected if every value comes from a single byte). What I find confusing is reconciling this with what I just did above. To make sense of it, I need to recall the code point to UTF-8 conversion table above, and bring in binary numbers. \n\nNote what happens when I try to convert the UTF-8 encoded bytes as if they were code points: \n\nEverything is ok up until we hit the Greek letter rho, Ï±. The problem here is that `chr()` is the reverse of `ord()` and so it only operates properly on code points, not UTF-8 bytes. To see this, we can use our earlier code point values:\n\nThat looks better! But how do I reconcile these two approaches. I'll first isolate our \"problem\" characters.\n\nI know that a space character, \" \", is represented by code point 32, so it seems that we have: \n1. Ï± somehow equivalent to two code points 207, 177\n2. à¤œ somehow equivalent to three code points 224, 164, 156\n3. ðŸ˜€somehow equivalent to the four code points 240, 159, 152, 128\n\n\nFor item 1 we could try:\n\nor\n\nNeither of those give the correct output. To get this to work I need to follow the UTF-8 guidelines for converting to Unicode code points (see [table above](#utf8-conversion)). So for the Greek letter, let's take a look at the byte values in binary and use the table to convert.\n<!-- ![unicode_to_utf8](UTF-8.png) -->\n\nThe $\\rm{\\textcolor{red}{0b}}$ is Python's designation for binary digit, and it is left out of the conversion table. So, instead of 207 and 177, we can deal 11001111 and 10110001. Now we can follow the UTF-8 encoding. The $\\textcolor{blue}{110}$ at the beginning of the first number is a code to indicate that the character requires two bytes ($\\textcolor{blue}{1110}$ if it requires three bytes and $\\textcolor{blue}{11110}$ if it requires four bytes). Any byte beginning with a $\\textcolor{blue}{10}$ denotes to Python that it belongs to a sequence of either 2, 3, or 4 bytes, and that it is NOT the starting byte (the source of many UnicodeDecodeErrors). Using this system, I get the following for Ï±:\n\n$$\n\\begin{align*}\n207 \\,\\, 177 &= \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{110}\\, 01111 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 110001 \\\\\n\\\\\n\\rm{binary\\,code\\, point\\, for\\,207\\,177}&= 01111 \\,\\,\\, 110001 \\\\\n&= 01111110001  \\\\\n\\rm{decimal\\,code\\, point\\, for\\,207\\,177}&= 0 \\times 2^{10} + 1 \\times 2^9 + 1 \\times 2^8 + 1 \\times 2^7 + 1 \\times 2^6 + 1 \\times 2^5 + 1 \\times 2^4 + 0 \\times 2^3 + 0 \\times 2^2 + 0 \\times 2^1 + 1 \\times 2^0 \\\\\n&= 0 + 512 + 256 + 128 + 64 + 32 + 16 + 0 + 0 + 0 + 1 \\\\\n&= 1009\n\\end{align*}\n$$\n\nAnd just to validate that calculation:\n\nThis approach, then, provides a mechanism from going from stored binary digits to Unicode code points. \n\nSince I am a skeptical person, I want to see if this works for my other two \"problem\" characters. This time, however, I will leave out the direct conversion to decimal values. For these two characters, I have the following byte values:\n\nFor à¤œ, I get the following:\n\n$$\n\\begin{align*}\n224 \\,\\, 164\\,\\,156 &= \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{1110}\\, 0000 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 100100 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 011100\\\\\n\\\\\n\\rm{binary\\,code\\, point\\, for\\,224 \\,\\ 164\\,\\,156}&= 0000 \\,\\,\\, 100100 \\,\\,\\, 011100 \\\\\n&= 0000100100011100  \\\\\n\\end{align*}\n$$\n\nwhich equals\n\nAnd for ðŸ˜€, I get:\n\n\n$$\n\\begin{align*}\n240\\,\\,159 \\,\\, 152\\,\\,128 &= \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{11110}\\, 000 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 011111 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\, 011000 \\,\\,\\, \\rm{\\textcolor{red}{0b}}\\, \\textcolor{blue}{10}\\,000000\\\\\n\\\\\n\\rm{binary\\,code\\, point\\, for\\,240\\,\\,159 \\,\\, 152\\,\\,128}&= 000 \\,\\,\\, 011111 \\,\\,\\, 011000 \\,\\,\\, 000000 \\\\\n&= 000011111011000000000  \\\\\n\\end{align*}\n$$\n\nwhich is\n\nSo, I can see that everything is working as it is supposed to. \n\nBefore wrapping up this part of my journey, I want to mention that UTF-8 is not the only encoding scheme. UTF-16 and UTF-32 also exist. However, since UTF-8 seems to be the [dominant encoding scheme](https://w3techs.com/technologies/overview/character_encoding) at the moment, I won't venture into the lands of UTF-16 and UTF-32. \n\nAnd the last point I want to make is that the 2, 3, and 4 byte sequences used in UTF-8 are linked bytes, so all is well if I execute\n\nBut not so good if I execute this\n\nThis is because the inserted space character is not a valid continuation byte according the the UTF-8 scheme. \n\nWell, that is it for the first part of my journey to dig into the details of BPE. Some aspects of encoding are still a bit murky, but I think I grasp enough at the moment to move on. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"BPE_Part_1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","theme":"cosmo","title-block-banner":true,"title":"Understanding Byte Pair Encoding: Part 1: Encodings","author":"Mark Cassar","date":"18 December 2024"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}