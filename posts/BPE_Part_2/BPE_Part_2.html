<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mark Cassar">
<meta name="dcterms.date" content="2001-12-23">

<title>Understanding Byte Pair Encoding: Part 2: Tokenization – Filling in the Gaps</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-f3c2ea88cadbcfb37ba28ffa2c97cfc1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Filling in the Gaps</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Understanding Byte Pair Encoding: Part 2: Tokenization</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Mark Cassar </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 23, 2001</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="understanding-byte-pair-encoding-part-2-tokenization" class="level2">
<h2 class="anchored" data-anchor-id="understanding-byte-pair-encoding-part-2-tokenization">Understanding Byte Pair Encoding: Part 2: Tokenization</h2>
<p>In my last post, I discussed encoding text, specifically using UTF-8. As I noted there, this encoding uses 1 to 4 bytes to represent all the characters in the Unicode system. This will be the <em>byte</em> part of <em>byte pair encoding (BPE)</em>, which was introduced by Sennrich, Haddow, and Birch in a paper entitled <a href="https://arxiv.org/abs/1508.07909">Neural Machine Translation of Rare Words with Subword Units</a> in 2015 (although the official publication was in 2016). It was proposed as a solution to the open vocabulary problem in machine translation. The method is an adaptation of a data compression technique developed by <a href="https://www.semanticscholar.org/paper/A-new-algorithm-for-data-compression-Gage/1aa9c0045f1fe8c79cce03c7c14ef4b4643a21f8">Philip Gage</a> back in 1994.</p>
<p>Rare and out-of-vocabulary (OOV) words are a known issue when dealing with language, so the proposal was to tokenize text in a way that allows for subword units. In this way, rare or OOV words could be composed of the subunits. Sennrich et al.&nbsp;showed that this approach gave better results than prior methods.</p>
<p>Now, instead of <em>encodings</em> and <em>bytes</em> I want to come to grips with the terms <em>vocabulary</em>, <em>out-of-vocabulary</em>, and <em>tokenize</em>: what do they mean and why do I need them?</p>
<p>I understand that large language models (LLMs) perform mathematical operations on their input to produce their output. So, it makes sense that they cannot process raw text. But, why not just use the numbers that come out of the UTF-8 encoding? The two main reasons against that approach that I can think of are:</p>
<ul>
<li>encodings are about characters, not meaning; for example, ‘dog’ and ‘canine’ have similar meaning but very different encodings; likewise, ‘act’ and ‘cat’ would have similar encodings but have very different meanings; and</li>
<li>in order to process any text we would need about 1 million numbers, which would drastically increase the computation required (compared to current methods)</li>
</ul>
<section id="tokenization" class="level3">
<h3 class="anchored" data-anchor-id="tokenization">Tokenization</h3>
<p>To get to a better numeric representation of text, the usual starting point is <em>tokenization.</em> Tokenization is the process of breaking up text into smaller pieces called <em>tokens</em>, where a token is the smallest unit of text. Once it’s decided what a token should be, the set of unique tokens represents the <em>vocabulary</em>. The idea then is that given any raw text, I can represent it as a sequence of tokens from the vocabulary.</p>
<p>The process so far is:</p>
<ul>
<li>define what is meant by a token</li>
<li>gather text that can be used as training data</li>
<li>break the training data into tokens</li>
<li>create a vocabulary from the unique set of tokens</li>
<li>break up any new text into tokens from this vocabulary</li>
</ul>
<p>It is a good time to try this out, so, I’ll grab some text that is in the public domain:</p>
<div id="cell-5" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://www.gutenberg.org/cache/epub/2814/pg2814.txt"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(url)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> response.text</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>text</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> text[<span class="dv">1069</span>:].replace(<span class="st">"</span><span class="ch">\r\n</span><span class="st">"</span>, <span class="st">" "</span>).replace(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>, <span class="st">" "</span>) <span class="co"># remove front matter and get rid of 'carriage' returns, ie. new lines</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>par <span class="op">=</span> text[:<span class="dv">903</span>] <span class="co"># grab the first paragraph</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>par</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>'THE SISTERS   There was no hope for him this time: it was the third stroke. Night after night I had passed the house (it was vacation time) and studied the lighted square of window: and night after night I had found it lighted in the same way, faintly and evenly. If he was dead, I thought, I would see the reflection of candles on the darkened blind for I knew that two candles must be set at the head of a corpse. He had often said to me: “I am not long for this world,” and I had thought his words idle. Now I knew they were true. Every night as I gazed up at the window I said softly to myself the word paralysis. It had always sounded strangely in my ears, like the word gnomon in the Euclid and the word simony in the Catechism. But now it sounded to me like the name of some maleficent and sinful being. It filled me with fear, and yet I longed to be nearer to it and to look upon its deadly work'</code></pre>
</div>
</div>
<p>I am going to ignore punctuation and define a token as a word:</p>
<div id="cell-7" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>punct <span class="op">=</span> string.punctuation</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>par_no_punct <span class="op">=</span> <span class="st">''</span>.join(c <span class="cf">for</span> c <span class="kw">in</span> par <span class="cf">if</span> c <span class="kw">not</span> <span class="kw">in</span> string.punctuation)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>par_tokens <span class="op">=</span> par_no_punct.split()  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(par_tokens))</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(par_tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>183
['THE', 'SISTERS', 'There', 'was', 'no', 'hope', 'for', 'him', 'this', 'time', 'it', 'was', 'the', 'third', 'stroke', 'Night', 'after', 'night', 'I', 'had', 'passed', 'the', 'house', 'it', 'was', 'vacation', 'time', 'and', 'studied', 'the', 'lighted', 'square', 'of', 'window', 'and', 'night', 'after', 'night', 'I', 'had', 'found', 'it', 'lighted', 'in', 'the', 'same', 'way', 'faintly', 'and', 'evenly', 'If', 'he', 'was', 'dead', 'I', 'thought', 'I', 'would', 'see', 'the', 'reflection', 'of', 'candles', 'on', 'the', 'darkened', 'blind', 'for', 'I', 'knew', 'that', 'two', 'candles', 'must', 'be', 'set', 'at', 'the', 'head', 'of', 'a', 'corpse', 'He', 'had', 'often', 'said', 'to', 'me', '“I', 'am', 'not', 'long', 'for', 'this', 'world”', 'and', 'I', 'had', 'thought', 'his', 'words', 'idle', 'Now', 'I', 'knew', 'they', 'were', 'true', 'Every', 'night', 'as', 'I', 'gazed', 'up', 'at', 'the', 'window', 'I', 'said', 'softly', 'to', 'myself', 'the', 'word', 'paralysis', 'It', 'had', 'always', 'sounded', 'strangely', 'in', 'my', 'ears', 'like', 'the', 'word', 'gnomon', 'in', 'the', 'Euclid', 'and', 'the', 'word', 'simony', 'in', 'the', 'Catechism', 'But', 'now', 'it', 'sounded', 'to', 'me', 'like', 'the', 'name', 'of', 'some', 'maleficent', 'and', 'sinful', 'being', 'It', 'filled', 'me', 'with', 'fear', 'and', 'yet', 'I', 'longed', 'to', 'be', 'nearer', 'to', 'it', 'and', 'to', 'look', 'upon', 'its', 'deadly', 'work']</code></pre>
</div>
</div>
<p>Based on defining a token at the word level, I have 183 tokens in my training data, which I took to be the first paragraph of the text. Now I would like to create the vocabulary, which is just the set of unique tokens:</p>
<div id="cell-9" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(par_tokens)))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(vocab))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vocab)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>109
['But', 'Catechism', 'Euclid', 'Every', 'He', 'I', 'If', 'It', 'Night', 'Now', 'SISTERS', 'THE', 'There', 'a', 'after', 'always', 'am', 'and', 'as', 'at', 'be', 'being', 'blind', 'candles', 'corpse', 'darkened', 'dead', 'deadly', 'ears', 'evenly', 'faintly', 'fear', 'filled', 'for', 'found', 'gazed', 'gnomon', 'had', 'he', 'head', 'him', 'his', 'hope', 'house', 'idle', 'in', 'it', 'its', 'knew', 'lighted', 'like', 'long', 'longed', 'look', 'maleficent', 'me', 'must', 'my', 'myself', 'name', 'nearer', 'night', 'no', 'not', 'now', 'of', 'often', 'on', 'paralysis', 'passed', 'reflection', 'said', 'same', 'see', 'set', 'simony', 'sinful', 'softly', 'some', 'sounded', 'square', 'strangely', 'stroke', 'studied', 'that', 'the', 'they', 'third', 'this', 'thought', 'time', 'to', 'true', 'two', 'up', 'upon', 'vacation', 'was', 'way', 'were', 'window', 'with', 'word', 'words', 'work', 'world”', 'would', 'yet', '“I']</code></pre>
</div>
</div>
<p>Using this vocabulary, I can now try to tokenize any new text:</p>
<div id="cell-11" class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_tokens(tokens, vocab):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> token <span class="kw">in</span> tokens:</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> token <span class="kw">in</span> vocab: </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="bu">chr</span>(<span class="dv">10004</span>), end<span class="op">=</span><span class="st">" "</span>) <span class="co">#f"\tToken = '{token}' is in the vocabulary")</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"(</span><span class="sc">{</span><span class="bu">chr</span>(<span class="dv">10006</span>)<span class="sc">}</span><span class="ss"> '</span><span class="sc">{</span>token<span class="sc">}</span><span class="ss">')"</span>, end<span class="op">=</span><span class="st">" "</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>new_text <span class="op">=</span> <span class="st">'I like to be on vacation'</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>new_text_tokens <span class="op">=</span> new_text.split()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New text: </span><span class="sc">{</span>new_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>new_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>check_tokens(new_text_tokens, vocab)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>New text: I like to be on vacation
Possible tokenization: ['I', 'like', 'to', 'be', 'on', 'vacation']

Check if all tokens are in the vocabulary:
✔ ✔ ✔ ✔ ✔ ✔ </code></pre>
</div>
</div>
</section>
<section id="out-of-vocabulary-words" class="level3">
<h3 class="anchored" data-anchor-id="out-of-vocabulary-words">Out-of-vocabulary words</h3>
<p>But what if I wanted to tokenize a different sentence?</p>
<div id="cell-14" class="cell" data-execution_count="132">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>diff_text <span class="op">=</span> <span class="st">"I hate to be on vacation"</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>diff_text_tokens <span class="op">=</span> diff_text.split()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Different text: </span><span class="sc">{</span>diff_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>diff_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>check_tokens(diff_text_tokens, vocab)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Different text: I hate to be on vacation
Possible tokenization: ['I', 'hate', 'to', 'be', 'on', 'vacation']

Check if all tokens are in the vocabulary:
✔ (✖ 'hate') ✔ ✔ ✔ ✔ </code></pre>
</div>
</div>
<p>I see I have run into the OOV problem! (I am tempted to say that no one hates to be on vacation so there really is no need to tokenize this sentence!) The text I am currently trying to tokenize contains a token (in this case, a word) that does not exist in my vocabulary. What happened?</p>
<p>Language is high-dimensional, that is, there are a lot of words. (And that is true just of English, not to mention all human languages.) Even though my example only considers a small amount of text as training data, to avoid this problem I would need to include all the text ever produced, which is not practical. Even that would only suffice until a new word was created and then I would be facing the OOV problem again. That is without even considering if that would be feasible computationally.</p>
</section>
<section id="rare-words" class="level3">
<h3 class="anchored" data-anchor-id="rare-words">Rare words</h3>
<p>Another issue arises if I try to make sure the vocabulary size doesn’t get too big. To do this, I can limit the vocabulary to tokens that occur at or above some threshold frequency. To see how this works, I’ll redo what I just did above, but this time I will only keep tokens in my vocabulary that occur more than once.</p>
<div id="cell-17" class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>t_freq <span class="op">=</span> {}</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token <span class="kw">in</span> par_tokens:</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    t_freq[token] <span class="op">=</span> t_freq.get(token, <span class="dv">0</span>) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>tokens_freq <span class="op">=</span> [token <span class="cf">for</span> token <span class="kw">in</span> t_freq.keys() <span class="cf">if</span> t_freq[token] <span class="op">&gt;</span> <span class="dv">1</span>]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>vocab_freq <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(tokens_freq)))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(vocab_freq))</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vocab_freq)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>27
['I', 'It', 'after', 'and', 'at', 'be', 'candles', 'for', 'had', 'in', 'it', 'knew', 'lighted', 'like', 'me', 'night', 'of', 'said', 'sounded', 'the', 'this', 'thought', 'time', 'to', 'was', 'window', 'word']</code></pre>
</div>
</div>
<p>Applying this new vocabulary to the same two sentences gives:</p>
<div id="cell-19" class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New text: </span><span class="sc">{</span>new_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>new_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>check_tokens(new_text_tokens, vocab_freq)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Different text: </span><span class="sc">{</span>diff_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>diff_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>check_tokens(diff_text_tokens, vocab_freq)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>New text: I like to be on vacation
Possible tokenization: ['I', 'like', 'to', 'be', 'on', 'vacation']

Check if all tokens are in the vocabulary:
✔ ✔ ✔ ✔ (✖ 'on') (✖ 'vacation') 

Different text: I hate to be on vacation
Possible tokenization: ['I', 'hate', 'to', 'be', 'on', 'vacation']

Check if all tokens are in the vocabulary:
✔ (✖ 'hate') ✔ ✔ (✖ 'on') (✖ 'vacation') </code></pre>
</div>
</div>
<p>I get the anticipated drop in vocabulary size from 109 to 27, however, I also see that now neither of the sentences can be properly tokenized. This is the <em>rare word</em> problem.</p>
<p>One way to deal with this is to always add a special token <code>&lt;|unk|&gt;</code> that can be used whenever I encounter a token that is not in the vocabulary.</p>
<p>For our current scenario, our sentences would be tokenized as follows:</p>
<div id="cell-21" class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>new_text_tokens <span class="op">=</span> [token <span class="cf">if</span> token <span class="kw">in</span> vocab_freq <span class="cf">else</span> <span class="st">'&lt;|unk|&gt;'</span> <span class="cf">for</span> token <span class="kw">in</span> new_text.split()]</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>diff_text_tokens <span class="op">=</span> [token <span class="cf">if</span> token <span class="kw">in</span> vocab_freq <span class="cf">else</span> <span class="st">'&lt;|unk|&gt;'</span> <span class="cf">for</span> token <span class="kw">in</span> diff_text.split()]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_text_tokens)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(diff_text_tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['I', 'like', 'to', 'be', '&lt;|unk|&gt;', '&lt;|unk|&gt;']
['I', '&lt;|unk|&gt;', 'to', 'be', '&lt;|unk|&gt;', '&lt;|unk|&gt;']</code></pre>
</div>
</div>
<p>This removes both the rare and OOV problems, but it is not ideal. Now, any not in my vocabulary gets assigned the exact same token, <code>&lt;|unk|&gt;</code>, and the model will treat them all identically regardless of their original meaning.</p>
</section>
<section id="go-bigger" class="level3">
<h3 class="anchored" data-anchor-id="go-bigger">Go bigger</h3>
<p>For current LLMs computation happens at the token level. As far as I can tell, this means that if a given piece of raw text can be represented by fewer tokens, then it requires less computation; or, if I fix the computational resources, then I can process more raw text at a time (the so-called context window).</p>
<p>If that is the case, maybe going bigger than word level would be a good idea. I’ll try sentences:</p>
<div id="cell-24" class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>sent <span class="op">=</span> re.split(<span class="vs">r'(?&lt;!\w\.\w.)(?&lt;![A-Z][a-z]\.)(?&lt;=\.|\?|!)\s'</span>, par)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>sent</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>vocab_sent <span class="op">=</span> []</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> s <span class="kw">in</span> sent:</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    cleaned_s <span class="op">=</span> <span class="st">''</span>.join(ch <span class="cf">for</span> ch <span class="kw">in</span> s <span class="cf">if</span> ch.isalnum() <span class="kw">or</span> ch.isspace())</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    vocab_sent.append(cleaned_s)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>vocab_sent</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="136">
<pre><code>['THE SISTERS   There was no hope for him this time it was the third stroke',
 'Night after night I had passed the house it was vacation time and studied the lighted square of window and night after night I had found it lighted in the same way faintly and evenly',
 'If he was dead I thought I would see the reflection of candles on the darkened blind for I knew that two candles must be set at the head of a corpse',
 'He had often said to me I am not long for this world and I had thought his words idle',
 'Now I knew they were true',
 'Every night as I gazed up at the window I said softly to myself the word paralysis',
 'It had always sounded strangely in my ears like the word gnomon in the Euclid and the word simony in the Catechism',
 'But now it sounded to me like the name of some maleficent and sinful being',
 'It filled me with fear and yet I longed to be nearer to it and to look upon its deadly work']</code></pre>
</div>
</div>
<p>Now, if I try to tokenize new text I’ll see that it will be very unlikely that tokenization will occur properly:</p>
<div id="cell-26" class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New text: </span><span class="sc">{</span>new_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>new_text_tokens <span class="op">=</span> [<span class="st">''</span>.join(ch <span class="cf">for</span> ch <span class="kw">in</span> new_text <span class="cf">if</span> ch.isalnum() <span class="kw">or</span> ch.isspace())]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>new_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>check_tokens(new_text_tokens, vocab_sent)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Different text: </span><span class="sc">{</span>diff_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>diff_text_tokens <span class="op">=</span> [<span class="st">''</span>.join(ch <span class="cf">for</span> ch <span class="kw">in</span> diff_text <span class="cf">if</span> ch.isalnum() <span class="kw">or</span> ch.isspace())]</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>diff_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>check_tokens(diff_text_tokens, vocab_sent)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>New text: I like to be on vacation
Possible tokenization: ['I like to be on vacation']

Check if all tokens are in the vocabulary:
(✖ 'I like to be on vacation') 

Different text: I hate to be on vacation
Possible tokenization: ['I hate to be on vacation']

Check if all tokens are in the vocabulary:
(✖ 'I hate to be on vacation') </code></pre>
</div>
</div>
<p>If it were to work, then every sentence of raw text would only be one token, which would be computationally efficient. However, to get it to work, my training data would have to cover all possible sentences, which would make the vocabulary impractically large.</p>
</section>
<section id="go-smaller" class="level3">
<h3 class="anchored" data-anchor-id="go-smaller">Go smaller</h3>
<p>What if, instead of making the tokens longer than words, I made them shorter? An obvious approach then would be to tokenize at the character level:</p>
<div id="cell-29" class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>vocab_ch <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(<span class="bu">list</span>(par))))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>vocab_ch <span class="op">=</span> [ch <span class="cf">for</span> ch <span class="kw">in</span> vocab_ch <span class="cf">if</span> ch.isalnum() <span class="kw">or</span> ch.isspace()]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vocab_ch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[' ', 'B', 'C', 'E', 'H', 'I', 'N', 'R', 'S', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z']</code></pre>
</div>
</div>
<p>Let’s see how this would work on my two sentences:</p>
<div id="cell-31" class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New text: </span><span class="sc">{</span>new_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>new_text_tokens <span class="op">=</span> <span class="bu">list</span>(<span class="st">''</span>.join(ch <span class="cf">for</span> ch <span class="kw">in</span> new_text <span class="cf">if</span> ch.isalnum() <span class="kw">or</span> ch.isspace()))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>new_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>check_tokens(new_text_tokens, vocab_ch)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Different text: </span><span class="sc">{</span>diff_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>diff_text_tokens <span class="op">=</span> <span class="bu">list</span>(<span class="st">''</span>.join(ch <span class="cf">for</span> ch <span class="kw">in</span> diff_text <span class="cf">if</span> ch.isalnum() <span class="kw">or</span> ch.isspace()))</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Possible tokenization: </span><span class="sc">{</span>diff_text_tokens<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Check if all tokens are in the vocabulary:"</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>check_tokens(diff_text_tokens, vocab_ch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>New text: I like to be on vacation
Possible tokenization: ['I', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'o', ' ', 'b', 'e', ' ', 'o', 'n', ' ', 'v', 'a', 'c', 'a', 't', 'i', 'o', 'n']

Check if all tokens are in the vocabulary:
✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ 

Different text: I hate to be on vacation
Possible tokenization: ['I', ' ', 'h', 'a', 't', 'e', ' ', 't', 'o', ' ', 'b', 'e', ' ', 'o', 'n', ' ', 'v', 'a', 'c', 'a', 't', 'i', 'o', 'n']

Check if all tokens are in the vocabulary:
✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ </code></pre>
</div>
</div>
<p>It works! And since all English words, by definition, can be constructed from the alphabet, I will never encounter a word that I cannot tokenize.</p>
<p>Before celebrating, I will do some comparisons using the text “I like to be on vacation”.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Tokenization Level</th>
<th style="text-align: center;">Number of Tokens</th>
<th style="text-align: center;">Relative Vocabulary Size</th>
<th style="text-align: center;">OOV/Rare Word Problems</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">character</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">small</td>
<td style="text-align: center;">no</td>
</tr>
<tr class="even">
<td style="text-align: center;">word</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">medium</td>
<td style="text-align: center;">yes</td>
</tr>
<tr class="odd">
<td style="text-align: center;">sentence</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">large</td>
<td style="text-align: center;">yes</td>
</tr>
</tbody>
</table>
<p>I conclude that the “no free lunch” axiom is correct. Removing some problems seems to potentially introduce problems somewhere else. For instance, tokenizing at the character level means there would be no such thing as OOV or rare word problems, but the cost is that for any give text there is a large increase in the number of tokens. So, if token count represents, on some level, computation then we need more computation for the same text then, say, word level tokenization. If I keep the computation level fixed, then character level tokenization will significantly reduce the context window, that is, how much text can be processed at the same time by the LLM.</p>
<p>I think of byte pair encoding as a smart compromise between character and word level tokenization. And that is what I’ll finally dig into next time.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/markcassar\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>